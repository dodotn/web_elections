"""
projekt3.py: t≈ôet√≠ projekt do Engeto Online Python Akademie

author: Jozef Drga
email: dodo.tn@seznam.cz
"""

import requests
from bs4 import BeautifulSoup
import csv
import sys
import re


def get_municipality_links(url: str) -> list:
    """Z√≠ska odkazy na obce z okresnej str√°nky."""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        response = requests.get(url, headers=headers)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"Chyba pri naƒç√≠tan√≠ URL: {url}")
        print(f"Detail chyby: {e}")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    links = soup.find_all('a', href=True)
    
    municipality_links = []
    for link in links:
        if not ('ps311' in link['href'] and 'xobec' in link['href']):
            continue
        link_to_add = 'https://www.volby.cz/pls/ps2017nss/' + link['href']
        if link_to_add not in municipality_links:
            municipality_links.append(link_to_add)
    
    #  Debug v√Ωpisy
    print(f"DEBUG - N√°jden√© odkazy na obce: {len(municipality_links)}")
    if municipality_links:
        print(f"Prv√Ω odkaz: {municipality_links[0]}")

    return municipality_links


def get_municipality_data(municipality_url: str) -> dict:
    """Extrahuje √∫daje o konkr√©tnej obci."""
    try:
        response = requests.get(municipality_url)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"Chyba pri naƒç√≠tan√≠ obce: {municipality_url}")
        print(f"Detail chyby: {e}")
        return {}

    soup = BeautifulSoup(response.text, 'html.parser')

    # üîπ Extrahovanie n√°zvu obce
    name = extract_municipality_name(soup, municipality_url)
    
    # üîπ Extrahovanie z√°kladn√Ωch √∫dajov
    basic_data = extract_basic_data(soup, municipality_url)
    
    # üîπ Extrahovanie volebn√Ωch v√Ωsledkov
    election_results = extract_election_results(soup)

    # üîπ Spojenie v≈°etk√Ωch d√°t do jedn√©ho slovn√≠ka
    return {**basic_data, 'N√°zov obce': name, **election_results}


def extract_municipality_name(soup: BeautifulSoup, url: str) -> str:
    """Z√≠ska n√°zov obce zo str√°nky."""
    name_tags = soup.find_all('h3')
    
    if len(name_tags) > 2:
        return name_tags[2].text.strip()
    
    print(f"Upozornenie: N√°zov obce sa nena≈°iel pre {url}")
    return "Nezn√°m√° obec"


def extract_basic_data(soup: BeautifulSoup, url: str) -> dict:
    """Z√≠ska z√°kladn√© √∫daje o obci."""
    basic_data_table = soup.find('table', {'class': 'table'})
    rows = basic_data_table.find_all('tr') if basic_data_table else []
    
    if not rows or len(rows) < 3:
        print(f"Upozornenie: Z√°kladn√© √∫daje sa nena≈°li pre {url}")
        return {}

    data_cells = rows[2].find_all('td')
    code = url.split('xobec=')[-1].split('&')[0]
    voters = clean_number(data_cells[3].text)
    envelopes = clean_number(data_cells[4].text)
    valid_votes = clean_number(data_cells[7].text)

    return {
        'K√≥d obce': code,
        'Voliƒçi v zozname': voters,
        'Odovzdane obalky': envelopes,
        'Platn√© hlasy': valid_votes
    }


def extract_election_results(soup: BeautifulSoup) -> dict:
    """Z√≠ska volebn√© v√Ωsledky str√°n."""
    results = {}
    
    party_table = soup.find_all('table')[-1]
    party_rows = party_table.find_all('tr')[2:] if party_table else []
    
    for row in party_rows:
        columns = row.find_all('td')
        if len(columns) > 2:
            party_name = columns[1].text.strip()
            votes = clean_number(columns[2].text)
            if party_name != '-':
                results[party_name] = votes
    
    return results


def clean_number(value: str) -> str:
    """Odstr√°ni medzery a neviditeƒæn√© znaky z ƒç√≠sla."""
    return value.strip().replace('\xa0', '').replace(' ', '')


def scrape_election_data(municipality_links: list) -> dict:
    """Spracuje volebn√© d√°ta a vr√°ti v slovn√≠ku. """
    all_data = []
    party_names = set()

    # Z√≠skanie √∫dajov pre ka≈æd√∫ obec
    for municipality_url in municipality_links:
        print(f" Spracov√°vam obec: {municipality_url}")
        municipality_data = get_municipality_data(municipality_url)
        
        if municipality_data:
            all_data.append(municipality_data)
            party_names.update(municipality_data.keys() - {'K√≥d obce', 'N√°zov obce', 'Voliƒçi v zozname', 'Odovzdane obalky', 'Platn√© hlasy'})
    
    return party_names, all_data


def save_election_data(party_names: dict, municipality_data: list, output_file: str) -> dict:
    #  Usporiadanie stƒ∫pcov v CSV
    sorted_party_names = sorted(party_names)
    header = ['K√≥d obce', 'N√°zov obce', 'Voliƒçi v zozname', 'Odovzdane obalky', 'Platn√© hlasy'] + sorted_party_names

    #  Ulo≈æenie do CSV
    with open(output_file, 'w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file, delimiter=',')
        writer.writerow(header)
        
        for row in municipality_data:
            sorted_row = [
                row.get('K√≥d obce', ''),
                row.get('N√°zov obce', ''),
                row.get('Voliƒçi v zozname', ''),
                row.get('Odovzdane obalky', ''),
                row.get('Platn√© hlasy', '')
            ] + [row.get(party, '0') for party in sorted_party_names]
            
            writer.writerow(sorted_row)

    print(f" √ödaje boli ulo≈æen√© do {output_file}.")


if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("üìå Pou≈æitie: python projekt3.py <url_okresu> <output_file>")
        sys.exit(1)

    url = sys.argv[1]
    output_file = sys.argv[2]

    if not re.match(r'^(http|https)://', url):
        print(" Chybn√Ω URL form√°t. Pros√≠m, zadajte platn√∫ URL.")
        sys.exit(1)

    municipality_links = get_municipality_links(url)

    if not municipality_links:
        print(" Neboli n√°jden√© ≈æiadne odkazy na obce.")
        sys.exit(1)

    parties, db = scrape_election_data(municipality_links)
    save_election_data(parties, db, output_file)
